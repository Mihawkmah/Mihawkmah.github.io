<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Scrapy爬虫入门[三] | 实战爬取时光网Top100电影 · 末小山 | 解锁产品&数据成就</title><meta name="description" content="Scrapy爬虫入门[三] | 实战爬取时光网Top100电影 - null"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="http://weibo.com/mihawkmah/atom.xml" title="末小山 | 解锁产品&amp;数据成就"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">我的</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">胶囊</a></li><li class="nav-list-item"><a href="http://mihawkmah.lofter.com/" target="_blank" class="nav-list-link">摄影</a></li><li class="nav-list-item"><a href="https://github.com/mihawkmah" target="_blank" class="nav-list-link">足迹</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Scrapy爬虫入门[三] | 实战爬取时光网Top100电影</h1><div class="post-info">2017年9月21日</div><div class="post-content"><h3 id="初始化爬虫"><a href="#初始化爬虫" class="headerlink" title="初始化爬虫"></a>初始化爬虫</h3><h4 id="抓取维度指标"><a href="#抓取维度指标" class="headerlink" title="抓取维度指标"></a>抓取维度指标</h4><ul>
<li>电影排名</li>
<li>电影名称</li>
<li>导演</li>
<li>主演</li>
<li>类型</li>
<li>电影描述</li>
<li>评分</li>
<li>评分人数</li>
</ul>
<h4 id="目标链接"><a href="#目标链接" class="headerlink" title="目标链接"></a>目标链接</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://www.mtime.com/top/movie/top100/</div></pre></td></tr></table></figure>
<a id="more"></a>
<h4 id="搭建爬虫"><a href="#搭建爬虫" class="headerlink" title="搭建爬虫"></a>搭建爬虫</h4><p><code>scrapy startproject mtime</code></p>
<h3 id="编写爬虫"><a href="#编写爬虫" class="headerlink" title="编写爬虫"></a>编写爬虫</h3><h4 id="iterms-py"><a href="#iterms-py" class="headerlink" title="iterms.py"></a>iterms.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">class MtimeItem(scrapy.Item):</div><div class="line">    rank = scrapy.Field()</div><div class="line">    name = scrapy.Field()</div><div class="line">    direct = scrapy.Field()</div><div class="line">    role = scrapy.Field()</div><div class="line">    type = scrapy.Field()</div><div class="line">    describe = scrapy.Field()</div><div class="line">    point = scrapy.Field()</div><div class="line">    pointnum = scrapy.Field()</div></pre></td></tr></table></figure>
<h4 id="配置settings-py"><a href="#配置settings-py" class="headerlink" title="配置settings.py"></a>配置settings.py</h4><p>使用chrome浏览器检查-Network查看Request Headers信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">USER_AGENT = &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36&apos;</div><div class="line"></div><div class="line">ROBOTSTXT_OBEY = False</div><div class="line"></div><div class="line">DOWNLOAD_DELAY = 3</div><div class="line"></div><div class="line">DEFAULT_REQUEST_HEADERS = &#123;</div><div class="line">   &apos;Accept&apos;: &apos;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&apos;,</div><div class="line">   &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.8&apos;,</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="在终端内测试提取数据"><a href="#在终端内测试提取数据" class="headerlink" title="在终端内测试提取数据"></a>在终端内测试提取数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">scrapy shell &apos;http://www.mtime.com/top/movie/top100_chinese/&apos;</div><div class="line"># 测试能否抓到数据</div><div class="line">response.css(&apos;div.mov_con&apos;)</div><div class="line"># response状态</div><div class="line">response.status</div></pre></td></tr></table></figure>
<h4 id="mtime-py"><a href="#mtime-py" class="headerlink" title="mtime.py"></a>mtime.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">from scrapy.spiders import Spider</div><div class="line">from mtime.items import MtimeItem</div><div class="line"></div><div class="line">class Mtime(Spider):</div><div class="line">    name = &apos;mtime&apos;</div><div class="line">    start_urls = [</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-2.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-3.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-4.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-5.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-6.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-7.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-8.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-9.html&apos;,</div><div class="line">        &apos;http://www.mtime.com/top/movie/top100/index-10.html&apos;</div><div class="line">    ]</div><div class="line"></div><div class="line">    def parse(self, response):</div><div class="line">        item = MtimeItem()</div><div class="line">        movies = response.css(&apos;ul#asyncRatingRegion li&apos;)</div><div class="line">        for movie in movies:</div><div class="line">            item[&apos;rank&apos;] = movie.css(&apos;div.number em::text&apos;)[0].extract()</div><div class="line">            item[&apos;name&apos;] = movie.css(&apos;h2 a::text&apos;)[0].extract()</div><div class="line">            item[&apos;direct&apos;] = movie.css(&apos;p a::text&apos;)[0].extract()</div><div class="line">            item[&apos;role&apos;] = movie.css(&apos;p&gt;a::text&apos;).extract()</div><div class="line">            item[&apos;type&apos;] = movie.css(&apos;span a::text&apos;).extract()</div><div class="line">            item[&apos;describe&apos;] = movie.css(&apos;p.mt3::text&apos;)[0].extract()</div><div class="line">            item[&apos;point&apos;] = movie.css(&apos;b.point span::text&apos;).extract()</div><div class="line">            item[&apos;pointnum&apos;] = movie.css(&apos;div.mov_point p::text&apos;)[0].extract()</div><div class="line">            yield item</div></pre></td></tr></table></figure>
<h3 id="存储数据"><a href="#存储数据" class="headerlink" title="存储数据"></a>存储数据</h3><h4 id="配置settings文件"><a href="#配置settings文件" class="headerlink" title="配置settings文件"></a>配置settings文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ITEM_PIPELINES = &#123;</div><div class="line">   &apos;mtime.pipelines.MongoPipeline&apos;: 300,</div><div class="line">&#125;</div><div class="line">MONGODB_SERVER = &quot;localhost&quot;</div><div class="line">MONGODB_PORT = 27017</div><div class="line">MONGODB_COLLECTION = &quot;movietop100&quot;</div><div class="line">MONGODB_DB = &quot;mtime&quot;</div></pre></td></tr></table></figure>
<h4 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py"></a>pipelines.py</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">import pymongo</div><div class="line">from scrapy.conf import settings</div><div class="line"></div><div class="line">class MongoPipeline(object):</div><div class="line">    def __init__(self):</div><div class="line">        connection = pymongo.MongoClient(</div><div class="line">            settings[&apos;MONGODB_SERVER&apos;],</div><div class="line">            settings[&apos;MONGODB_PORT&apos;]</div><div class="line">        )</div><div class="line">        db = connection[settings[&apos;MONGODB_DB&apos;]]</div><div class="line">        self.collection = db[settings[&apos;MONGODB_COLLECTION&apos;]]</div><div class="line">    def process_item(self, item, spider):</div><div class="line">        self.collection.insert(dict(item))</div><div class="line">        return item</div></pre></td></tr></table></figure>
<h3 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h3><p><code>scrapy crawl mtime</code></p>
<blockquote>
<p>GitHub项目 <a href="https://github.com/Mihawkmah/Python.Crawler" target="_blank" rel="external">https://github.com/Mihawkmah/Python.Crawler</a></p>
</blockquote>
<h4 id="附录：mongodb数据库操作指令"><a href="#附录：mongodb数据库操作指令" class="headerlink" title="附录：mongodb数据库操作指令"></a>附录：mongodb数据库操作指令</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">show dbs //显示数据库</div><div class="line">use testdb //创建或使用某个数据库</div><div class="line">db.dropDatabase() //删除数据库</div><div class="line"></div><div class="line">show tables //显示集合</div><div class="line">db.test.drop() //删除集合</div><div class="line">db.test.insert() //插入文档</div><div class="line">db.test.update() //更新文档</div><div class="line">db.test.remove() //删除文档</div><div class="line"></div><div class="line">db.test.find().pretty()   //查找文档</div><div class="line">(&gt;) 大于 - $gt</div><div class="line">(&lt;) 小于 - $lt</div><div class="line">(&gt;=) 大于等于 - $gte</div><div class="line">(&lt;= ) 小于等于 - $lte</div><div class="line">db.test.find().limit() //读取的记录条数</div><div class="line">db.test.find().skip() //跳过的记录条数</div><div class="line">db.test.find().sort() //排序</div></pre></td></tr></table></figure>
</div></article></div></main><footer><div class="paginator"><a href="/2017/09/30/Scrapy爬虫入门-四-Pandas数据分析Top100电影/" class="prev">上一篇</a><a href="/2017/09/18/利用海盗模型建立数据分析维度/" class="next">下一篇</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'mihawkmah';
var disqus_identifier = '2017/09/21/Scrapy爬虫入门-三-实战爬取时光网Top100电影/';
var disqus_title = 'Scrapy爬虫入门[三] | 实战爬取时光网Top100电影';
var disqus_url = 'http://weibo.com/mihawkmah/2017/09/21/Scrapy爬虫入门-三-实战爬取时光网Top100电影/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//mihawkmah.disqus.com/count.js" async></script><div class="copyright"><p>© 2017 - 2018 <a href="http://weibo.com/mihawkmah"></a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>